{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been tested on Amazon SageMaker Studio (ml.t3.medium = default) with kernel `Python 3 (Data Science)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `mxnet_recordio_sagemaker.py` in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "from mxnet import gluon\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::963310897349:role/service-role/AmazonSageMaker-ExecutionRole-20200629T125326'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pygmentize mxnet_recordio_sagemaker.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nm = MXNet(\"mxnet_recordio_sagemaker.py\",\\n          role=role,\\n          train_instance_count=1,\\n          train_instance_type=\"ml.c4.xlarge\",\\n          framework_version=\"1.6.0\",\\n          py_version=\"py3\",\\n          hyperparameters={\\'batch-size\\': 128,\\n                          \\'cuda\\': False})'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CPU Training\n",
    "\"\"\"\n",
    "m = MXNet(\"mxnet_recordio_sagemaker.py\",\n",
    "          role=role,\n",
    "          train_instance_count=1,\n",
    "          train_instance_type=\"ml.c4.xlarge\",\n",
    "          framework_version=\"1.6.0\",\n",
    "          py_version=\"py3\",\n",
    "          hyperparameters={'batch-size': 128,\n",
    "                          'cuda': False})\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Training\n",
    "\n",
    "m = MXNet(\"mxnet_recordio_sagemaker.py\",\n",
    "          role=role,\n",
    "          train_instance_count=1,\n",
    "          train_instance_type=\"ml.p3.2xlarge\",\n",
    "          framework_version=\"1.6.0\",\n",
    "          py_version=\"py3\",\n",
    "          train_use_spot_instances=True,\n",
    "          train_max_run=300,\n",
    "          train_max_wait=600,\n",
    "          hyperparameters={'batch-size': 128,\n",
    "                          'cuda': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## CHANGE THE FOLLOWING CELL WITH YOUR BUCKET NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-10 11:44:40 Starting - Starting the training job......\n",
      "2020-07-10 11:45:21 Starting - Launching requested ML instances......\n",
      "2020-07-10 11:46:26 Starting - Preparing the instances for training......\n",
      "2020-07-10 11:47:18 Downloading - Downloading input data...\n",
      "2020-07-10 11:47:50 Training - Downloading the training image...\n",
      "2020-07-10 11:48:31 Training - Training image download completed. Training in progress.\u001b[34m2020-07-10 11:48:32,174 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2020-07-10 11:48:32,205 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"batch-size\":128,\"cuda\":true}', 'SM_USER_ENTRY_POINT': 'mxnet_recordio_sagemaker.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"training\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'mxnet_recordio_sagemaker', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '8', 'SM_NUM_GPUS': '1', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-eu-west-1-963310897349/mxnet-training-2020-07-10-11-44-40-446/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":128,\"cuda\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-07-10-11-44-40-446\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-963310897349/mxnet-training-2020-07-10-11-44-40-446/source/sourcedir.tar.gz\",\"module_name\":\"mxnet_recordio_sagemaker\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mxnet_recordio_sagemaker.py\"}', 'SM_USER_ARGS': '[\"--batch-size\",\"128\",\"--cuda\",\"True\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_HP_BATCH-SIZE': '128', 'SM_HP_CUDA': 'true'}\u001b[0m\n",
      "\u001b[34m2020-07-10 11:48:32,543 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-07-10 11:48:32,543 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-07-10 11:48:32,543 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-07-10 11:48:32,543 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpa7gsv236/module_dir\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\n",
      "    Running setup.py install for default-user-module-name: started\n",
      "    Running setup.py install for default-user-module-name: finished with status 'done'\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-07-10 11:48:34,934 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 128,\n",
      "        \"cuda\": true\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"mxnet-training-2020-07-10-11-44-40-446\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-963310897349/mxnet-training-2020-07-10-11-44-40-446/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mxnet_recordio_sagemaker\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mxnet_recordio_sagemaker.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":128,\"cuda\":true}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mxnet_recordio_sagemaker.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mxnet_recordio_sagemaker\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-west-1-963310897349/mxnet-training-2020-07-10-11-44-40-446/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":128,\"cuda\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-07-10-11-44-40-446\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-963310897349/mxnet-training-2020-07-10-11-44-40-446/source/sourcedir.tar.gz\",\"module_name\":\"mxnet_recordio_sagemaker\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mxnet_recordio_sagemaker.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"128\",\"--cuda\",\"True\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_CUDA=true\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 mxnet_recordio_sagemaker.py --batch-size 128 --cuda True\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:root:Namespace(batch_size=128, cuda=True, current_host='algo-1', dtype='float32', epochs=10, hosts=['algo-1'], log_interval=100, lr=0.02, model_dir='/opt/ml/model', momentum=0.9, num_workers=4, rec_train='', rec_val='', seed=999, train='/opt/ml/input/data/training', val_interval=1)\u001b[0m\n",
      "\u001b[34mINFO:root:Running the script on single GPU\u001b[0m\n",
      "\u001b[34m[2020-07-10 11:48:45.348 ip-10-0-89-135.eu-west-1.compute.internal:39 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-07-10 11:48:45.349 ip-10-0-89-135.eu-west-1.compute.internal:39 INFO hook.py:170] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-07-10 11:48:45.349 ip-10-0-89-135.eu-west-1.compute.internal:39 INFO hook.py:215] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-07-10 11:48:45.367 ip-10-0-89-135.eu-west-1.compute.internal:39 INFO hook.py:351] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-07-10 11:48:45.506 ip-10-0-89-135.eu-west-1.compute.internal:39 INFO hook.py:226] Registering hook for block sigmoidbinarycrossentropyloss0\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 0 Batch 0] Training_Loss: 1.043359 Training_Acc: 0.539062\u001b[0m\n",
      "\u001b[34mERROR:root:'NoneType' object has no attribute 'write'\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 0 Batch 100] Training_Loss: 0.302654 Training_Acc: 0.807008\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 0 Batch 200] Training_Loss: 0.205548 Training_Acc: 0.851835\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 0 Batch 300] Training_Loss: 0.250869 Training_Acc: 0.871756\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 0 Batch 400] Training_Loss: 0.224764 Training_Acc: 0.882871\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 0 Batch 500] Training_Loss: 0.115237 Training_Acc: 0.892169\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 0 Batch 600] Training_Loss: 0.182549 Training_Acc: 0.899373\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 0 Batch 700] Training_Loss: 0.131520 Training_Acc: 0.905336\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[0]#011Speed=7130.89 samples/sec #011Time cost=12.618897 secs\u001b[0m\n",
      "\u001b[34mINFO:root:Validation Accuracy: 0.887460\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 1 Batch 0] Training_Loss: 0.217474 Training_Acc: 0.914062\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 1 Batch 100] Training_Loss: 0.103844 Training_Acc: 0.957225\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 1 Batch 200] Training_Loss: 0.094207 Training_Acc: 0.955457\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 1 Batch 300] Training_Loss: 0.059046 Training_Acc: 0.956551\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 1 Batch 400] Training_Loss: 0.114151 Training_Acc: 0.956457\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 1 Batch 500] Training_Loss: 0.098762 Training_Acc: 0.956010\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 1 Batch 600] Training_Loss: 0.126797 Training_Acc: 0.956232\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 1 Batch 700] Training_Loss: 0.095687 Training_Acc: 0.956569\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[1]#011Speed=8719.13 samples/sec #011Time cost=10.320295 secs\u001b[0m\n",
      "\u001b[34mINFO:root:Validation Accuracy: 0.911986\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 2 Batch 0] Training_Loss: 0.094241 Training_Acc: 0.960938\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 2 Batch 100] Training_Loss: 0.091001 Training_Acc: 0.971689\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 2 Batch 200] Training_Loss: 0.098197 Training_Acc: 0.969683\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 2 Batch 300] Training_Loss: 0.115573 Training_Acc: 0.969087\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 2 Batch 400] Training_Loss: 0.043615 Training_Acc: 0.968828\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 2 Batch 500] Training_Loss: 0.046379 Training_Acc: 0.969405\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 2 Batch 600] Training_Loss: 0.082922 Training_Acc: 0.969192\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 2 Batch 700] Training_Loss: 0.061967 Training_Acc: 0.969452\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[2]#011Speed=8812.20 samples/sec #011Time cost=10.211303 secs\u001b[0m\n",
      "\u001b[34mINFO:root:Validation Accuracy: 0.911392\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 3 Batch 0] Training_Loss: 0.071783 Training_Acc: 0.976562\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 3 Batch 100] Training_Loss: 0.033765 Training_Acc: 0.977877\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 3 Batch 200] Training_Loss: 0.036619 Training_Acc: 0.978661\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 3 Batch 300] Training_Loss: 0.078704 Training_Acc: 0.977860\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 3 Batch 400] Training_Loss: 0.059650 Training_Acc: 0.977030\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 3 Batch 500] Training_Loss: 0.025701 Training_Acc: 0.976843\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 3 Batch 600] Training_Loss: 0.072448 Training_Acc: 0.976913\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 3 Batch 700] Training_Loss: 0.042667 Training_Acc: 0.977265\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[3]#011Speed=8775.62 samples/sec #011Time cost=10.253864 secs\u001b[0m\n",
      "\u001b[34mINFO:root:Validation Accuracy: 0.926919\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 4 Batch 0] Training_Loss: 0.023197 Training_Acc: 1.000000\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 4 Batch 100] Training_Loss: 0.098120 Training_Acc: 0.985535\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 4 Batch 200] Training_Loss: 0.028731 Training_Acc: 0.983559\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 4 Batch 300] Training_Loss: 0.035446 Training_Acc: 0.984297\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 4 Batch 400] Training_Loss: 0.046089 Training_Acc: 0.984005\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 4 Batch 500] Training_Loss: 0.093973 Training_Acc: 0.983408\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 4 Batch 600] Training_Loss: 0.036719 Training_Acc: 0.982399\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 4 Batch 700] Training_Loss: 0.028322 Training_Acc: 0.982257\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[4]#011Speed=8847.26 samples/sec #011Time cost=10.170830 secs\u001b[0m\n",
      "\u001b[34mINFO:root:Validation Accuracy: 0.921282\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 5 Batch 0] Training_Loss: 0.046820 Training_Acc: 0.984375\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 5 Batch 100] Training_Loss: 0.037822 Training_Acc: 0.984994\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 5 Batch 200] Training_Loss: 0.059725 Training_Acc: 0.985463\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 5 Batch 300] Training_Loss: 0.022352 Training_Acc: 0.984894\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 5 Batch 400] Training_Loss: 0.024793 Training_Acc: 0.984726\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 5 Batch 500] Training_Loss: 0.035566 Training_Acc: 0.985326\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 5 Batch 600] Training_Loss: 0.036848 Training_Acc: 0.985428\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 5 Batch 700] Training_Loss: 0.033941 Training_Acc: 0.985556\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[5]#011Speed=8769.13 samples/sec #011Time cost=10.261447 secs\u001b[0m\n",
      "\u001b[34mINFO:root:Validation Accuracy: 0.918414\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 6 Batch 0] Training_Loss: 0.031429 Training_Acc: 0.992188\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 6 Batch 100] Training_Loss: 0.025417 Training_Acc: 0.990718\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 6 Batch 200] Training_Loss: 0.006511 Training_Acc: 0.989622\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 6 Batch 300] Training_Loss: 0.038106 Training_Acc: 0.989592\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 6 Batch 400] Training_Loss: 0.049306 Training_Acc: 0.988973\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 6 Batch 500] Training_Loss: 0.013183 Training_Acc: 0.988351\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 6 Batch 600] Training_Loss: 0.092782 Training_Acc: 0.988301\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 6 Batch 700] Training_Loss: 0.019169 Training_Acc: 0.987964\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[6]#011Speed=8774.39 samples/sec #011Time cost=10.255306 secs\u001b[0m\n",
      "\u001b[34mINFO:root:Validation Accuracy: 0.917029\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 7 Batch 0] Training_Loss: 0.014576 Training_Acc: 0.992188\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 7 Batch 100] Training_Loss: 0.041988 Training_Acc: 0.990408\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 7 Batch 200] Training_Loss: 0.011869 Training_Acc: 0.990166\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 7 Batch 300] Training_Loss: 0.050515 Training_Acc: 0.990474\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 7 Batch 400] Training_Loss: 0.012110 Training_Acc: 0.990025\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 7 Batch 500] Training_Loss: 0.051598 Training_Acc: 0.990036\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 7 Batch 600] Training_Loss: 0.021500 Training_Acc: 0.989861\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 7 Batch 700] Training_Loss: 0.026730 Training_Acc: 0.989992\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[7]#011Speed=8813.83 samples/sec #011Time cost=10.209407 secs\u001b[0m\n",
      "\u001b[34mINFO:root:Validation Accuracy: 0.919502\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 8 Batch 0] Training_Loss: 0.003176 Training_Acc: 1.000000\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 8 Batch 100] Training_Loss: 0.010351 Training_Acc: 0.991569\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 8 Batch 200] Training_Loss: 0.025431 Training_Acc: 0.991877\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 8 Batch 300] Training_Loss: 0.008891 Training_Acc: 0.991642\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 8 Batch 400] Training_Loss: 0.015382 Training_Acc: 0.991817\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 8 Batch 500] Training_Loss: 0.030568 Training_Acc: 0.991938\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 8 Batch 600] Training_Loss: 0.019628 Training_Acc: 0.991460\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 8 Batch 700] Training_Loss: 0.016077 Training_Acc: 0.991073\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[8]#011Speed=8792.29 samples/sec #011Time cost=10.234420 secs\u001b[0m\n",
      "\u001b[34mINFO:root:Validation Accuracy: 0.914656\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 9 Batch 0] Training_Loss: 0.008715 Training_Acc: 1.000000\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 9 Batch 100] Training_Loss: 0.033782 Training_Acc: 0.993502\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 9 Batch 200] Training_Loss: 0.015165 Training_Acc: 0.993626\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 9 Batch 300] Training_Loss: 0.027066 Training_Acc: 0.992655\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 9 Batch 400] Training_Loss: 0.039881 Training_Acc: 0.992032\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 9 Batch 500] Training_Loss: 0.014156 Training_Acc: 0.991486\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 9 Batch 600] Training_Loss: 0.030623 Training_Acc: 0.991057\u001b[0m\n",
      "\u001b[34mINFO:root:[Epoch 9 Batch 700] Training_Loss: 0.030095 Training_Acc: 0.991151\u001b[0m\n",
      "\u001b[34mINFO:root:Epoch[9]#011Speed=8793.40 samples/sec #011Time cost=10.233134 secs\u001b[0m\n",
      "\u001b[34mINFO:root:Validation Accuracy: 0.920194\u001b[0m\n",
      "\u001b[34m[2020-07-10 11:50:40.662 ip-10-0-89-135.eu-west-1.compute.internal:39 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-07-10 11:50:41,312 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-07-10 11:50:54 Uploading - Uploading generated training model\n",
      "2020-07-10 11:50:54 Completed - Training job completed\n",
      "Training seconds: 216\n",
      "Billable seconds: 65\n",
      "Managed Spot Training savings: 69.9%\n"
     ]
    }
   ],
   "source": [
    "m.fit('s3://YOURBUCKET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
