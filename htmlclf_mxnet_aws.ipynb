{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Environment (conda_mxnet_p36)",
      "language": "python",
      "name": "conda_mxnet_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "htmlclf_mxnet_aws.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathresearch/mlsec/blob/master/htmlclf_mxnet_aws.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTpmZQtVLIo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!aws s3 sync s3://mlsec/htmldata.tar.gz ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bp_UteyPcm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data\n",
        "!tar -xzf htmldata.tar.gz -C data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1YXDSWaGYbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mmh3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wfEw3CEGYbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import mmh3\n",
        "import time\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "from mxnet import gluon, autograd\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jux-01-gGYbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Custom dataset to load the data\n",
        "class CustomDataset(gluon.data.Dataset):\n",
        "    def __init__(self, path_to_b_files, path_to_m_files, features_size=1024):\n",
        "        self.features_size = features_size\n",
        "        b_files = [os.path.join(path_to_b_files, f) for f in os.listdir(path_to_b_files)]\n",
        "        m_files = [os.path.join(path_to_m_files, f) for f in os.listdir(path_to_m_files)]\n",
        "        self.list_files = b_files + m_files\n",
        "        self.length = len(self.list_files)\n",
        "        self.labels = mx.nd.concat(mx.nd.zeros(shape=(len(b_files))),\n",
        "                                   mx.nd.ones(shape=(len(m_files))),\n",
        "                                   dim=0)\n",
        "\n",
        "    def _extract_features(self, string, hash_dim, split_regex=rb\"\\s+\"):\n",
        "        tokens = re.split(pattern=split_regex, string=string)\n",
        "        hash_buckets = [(mmh3.hash(w) % hash_dim) for w in tokens]\n",
        "        buckets, counts = np.unique(hash_buckets, return_counts=True)\n",
        "        feature_values = np.zeros(hash_dim)\n",
        "        for bucket, count in zip(buckets, counts):\n",
        "            feature_values[bucket] = count\n",
        "        return feature_values\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        with open(self.list_files[idx], 'rb') as f:\n",
        "            content = f.read()\n",
        "        data = self._extract_features(content, hash_dim=self.features_size, split_regex=rb\"\\s+\")\n",
        "        return mx.nd.array(data), self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N9YfgWYGYbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Contants\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "LOG_INTERVAL = 100\n",
        "VAL_INTERVAL = 1\n",
        "\n",
        "# Fixed the seed for randomness\n",
        "mx.random.seed(999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfHltABYGYbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to get train and val dataloader\n",
        "def get_dataloader():\n",
        "    path_to_train_b_files = 'data/html/benign_files/training/'\n",
        "    path_to_train_m_files = 'data/html/malicious_files/training/'\n",
        "    path_to_validation_b_files = 'data/html/benign_files/validation/'\n",
        "    path_to_validation_m_files = 'data/html/malicious_files/validation/'\n",
        "    FEATURES_SIZE = 1024\n",
        "\n",
        "    train_dataset = CustomDataset(path_to_train_b_files,\n",
        "                                  path_to_train_m_files,\n",
        "                                  FEATURES_SIZE)\n",
        "    train_dataloader = mx.gluon.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                                                num_workers=8, shuffle=True)\n",
        "\n",
        "    val_dataset = CustomDataset(path_to_validation_b_files,\n",
        "                                path_to_validation_m_files,\n",
        "                                FEATURES_SIZE)\n",
        "    val_dataloader = mx.gluon.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
        "                                              num_workers=8, shuffle=False)\n",
        "\n",
        "    return train_dataloader, val_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzMwozMhGYbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to define neural network\n",
        "def custom_model():\n",
        "    net = gluon.nn.HybridSequential()\n",
        "    with net.name_scope():\n",
        "        net.add(gluon.nn.Dense(1024, activation='relu'))\n",
        "        net.add(gluon.nn.Dense(512, activation='relu'))\n",
        "        net.add(gluon.nn.Dense(1, activation='sigmoid'))\n",
        "    return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRXO2UAiGYbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to get binary labels\n",
        "def facc(label, pred):\n",
        "    pred = pred.ravel()\n",
        "    label = label.ravel()\n",
        "    return ((pred > 0.5) == label).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vca0kQ90GYb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to evaluate accuracy for a model\n",
        "def evaluate(model, val_data, ctx):\n",
        "    metric = mx.metric.CustomMetric(facc)\n",
        "    for data, label in val_data:\n",
        "        data = data.as_in_context(ctx)\n",
        "        label = label.as_in_context(ctx)\n",
        "        output = model(data)\n",
        "        metric.update(label, output)\n",
        "\n",
        "    return metric.get()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s4Aa_0KGYb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if mx.context.num_gpus() > 0:\n",
        "    logging.info(\"Running the script on single GPU\")\n",
        "    ctx = mx.gpu(0)\n",
        "else:\n",
        "    logging.info(\"Running the script on CPU\")\n",
        "    ctx = mx.cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_kTeNhAGYb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a model\n",
        "net = custom_model()\n",
        "net.cast('float32')\n",
        "net.hybridize(static_alloc=True, static_shape=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCPBvqFvGYb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize parameters\n",
        "initializer = mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\",\n",
        "                             magnitude=2)\n",
        "net.initialize(initializer, ctx=ctx)\n",
        "\n",
        "# Create optimizer\n",
        "optimizer_params = {'learning_rate': 0.02, 'momentum': 0.9}\n",
        "\n",
        "opt = mx.optimizer.create('sgd', **optimizer_params)\n",
        "trainer = gluon.Trainer(net.collect_params(), opt)\n",
        "loss_fn = gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O396agq5GYb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader, val_dataloader = get_dataloader()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxCPrxPKGYcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to train the model\n",
        "def train(net, train_dataloader, val_dataloader):\n",
        "    train_metric = mx.metric.CustomMetric(facc)\n",
        "    start = time.time() #B\n",
        "    for epoch in range(EPOCHS):\n",
        "        tic = time.time()\n",
        "        # reset metric at beginning of epoch.\n",
        "        train_metric.reset()\n",
        "        for i, (data, label) in enumerate(train_dataloader):\n",
        "            # Copy data to ctx if necessary\n",
        "            data = data.as_in_context(ctx)\n",
        "            label = label.as_in_context(ctx)\n",
        "\n",
        "            # Start recording computation graph with record() section.\n",
        "            # Recorded graphs can then be differentiated with backward.\n",
        "            with autograd.record():\n",
        "                output = net(data)\n",
        "                L = loss_fn(output, label)\n",
        "            L.backward()\n",
        "            curr_loss = mx.ndarray.mean(L).asscalar()\n",
        "\n",
        "            # take a gradient step with batch_size equal to data.shape[0]\n",
        "            trainer.step(BATCH_SIZE)\n",
        "            # update metric at last.\n",
        "            train_metric.update(label, output)\n",
        "\n",
        "            if i % LOG_INTERVAL == 0:\n",
        "                name, acc = train_metric.get()\n",
        "                logging.info('[Epoch %d Batch %d] Training_Loss: %f Training_Acc: %f' %\n",
        "                             (epoch, i, curr_loss, acc))\n",
        "        elapsed = time.time() - tic\n",
        "        speed = i * BATCH_SIZE / elapsed\n",
        "        logging.info('Epoch[%d]\\tSpeed=%.2f samples/sec \\tTime cost=%f secs',\n",
        "                     epoch+1, speed, elapsed)\n",
        "        \n",
        "        # Evaluate the model\n",
        "        if (epoch + 1) % VAL_INTERVAL == 0:\n",
        "            val_name, val_acc = evaluate(net, val_dataloader, ctx)\n",
        "            logging.info('Validation Accuracy: %f' % (val_acc))\n",
        "    logging.info('Total:%f' % (time.time()-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0JCHvgZGYcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(net, train_dataloader, val_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}